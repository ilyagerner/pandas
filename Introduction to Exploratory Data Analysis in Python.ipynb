{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Data Science?\n",
    "\n",
    "The hot takes via [Twitter](https://twitter.com/mcmoots/status/429318287864770560):\n",
    "\n",
    "- \"A data scientist is a statistician who lives in San Francisco.\" \n",
    "- \"A data scientist is a business analyst who lives in New York.\"\n",
    "- \"Data Science is statistics on a Mac.\"\n",
    "\n",
    "A more idealistic view:\n",
    "\n",
    "![Venn Diagram of Data Science](https://raw.githubusercontent.com/jakevdp/PythonDataScienceHandbook/8a34a4f653bdbdc01415a94dc20d4e9b97438965/notebooks/figures/Data_Science_VD.png)\n",
    "\n",
    "\"...think of data science not as a new domain of knowledge to learn, but a new set of skills that you can apply within your current area of expertise.\" - [Jake VanderPlas](http://vanderplas.com/), Director of Open Software at the University of Washington's eScience Institute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So what's the plan?\n",
    "\n",
    "We're going to combine a touch of stats, a hint of hacking, and a pinch of substantive knowledge about policing to analyze a real data set, collected by researchers at the [Stanford Open Policing Project](https://openpolicing.stanford.edu/).\n",
    "\n",
    "On a typical day in the United States, police officers make more than **50,000 traffic stops**. Stanford has collected over 200 million records from dozens of state and local police departments across the country in an effort to create a centralized repository detailing interactions between civilians and police. \n",
    "\n",
    "We're going to look at a subset of this data: **Maryland in 2013-2014, excluding the City of Baltimore.**\n",
    "\n",
    "Why just a subset? It keeps the size manageable, plus we avoid the sparse sections of the MD dataset. From Stanford:\n",
    "\n",
    "> The [Maryland] data is very messy. It comes from three different time periods: 2007, 2009-2012, 2013-2014. They all have different column and slightly different conventions of how things are recorded. We attempted to standardize the fields as much as possible.\n",
    "Time resolution of the data varies by year. Prior to 2013, data is reported annually. From 2013 onward, data is reported daily. So stop dates prior to 2013 are not precise to the nearest day and are just reported as Jan 1.\n",
    "Counties were mapped by running the police departments in the Agency field through Google's geocoder, but this does not work for state patrol stops, for which we have no county information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import packages\n",
    "See all the \"as ...\" contructs? They're just aliasing the package names.\n",
    "\n",
    "That way we can call methods like plt.plot() instead of matplotlib.pyplot.plot().\n",
    "\n",
    "The aliases used here are conventional in the Python data community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "# Above line is not necessary in latest version of Notebook, but in older versions\n",
    "# ensures that plots are displayed inline, not in a separate window\n",
    "\n",
    "import numpy as np # imports a fast numerical programming library\n",
    "import matplotlib as mpl # this actually imports matplotlib\n",
    "import matplotlib.pyplot as plt # sets up plotting under plt\n",
    "import pandas as pd #lets us handle data as dataframes\n",
    "import seaborn as sns #sets up styles and gives us more plotting options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boilerplate that sets some display options. The defaults are fine too!\n",
    "pd.set_option('display.width', 100)\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_rows', 25)\n",
    "pd.set_option('display.notebook_repr_html', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an f-string. If it doesn't work, you're running a Python version below 3.6. Consider upgrading!\n",
    "print(f\"Numpy Version: {np.__version__}, Pandas Version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import data\n",
    "\n",
    "Why `low_memory = False`? Inferring datatypes is very memory intensive and we're only specifying some of the dtypes during import. This suppresses a warning about memory use when we load data without specifying all dtypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = pd.read_csv('md_traffic.csv', low_memory = False, dtype={\n",
    "    'subject_age': 'float64',\n",
    "    'subject_race': 'category',\n",
    "    'subject_sex': 'category',\n",
    "    'arrest_made': 'bool',\n",
    "    'outcome': 'category',\n",
    "    'search_conducted': 'bool',\n",
    "    'reason_for_arrest': 'category',\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aside: Did you know you can measure execution time of small code snippets using the `%timeit` command?\n",
    "\n",
    "Notice that `timeit` executes the code several times and takes an average of the runs.\n",
    "Read more about it in the [official documentation](https://docs.python.org/3.7/library/timeit.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "%timeit array = [random.randint(0, 10) for i in range(100000)]\n",
    "%timeit values = np.random.randint(0, 10, 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aside #2: Did you know you can access a function's signature & docstring by adding a \"?\" after a command. E.g. `pd.read_csv?`\n",
    "It's the equivalent of `print(pd.read_csv.__doc__)` but `?` is a shortcut in the IPython environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'read_csv' is a Crime Against Nature masquerading as a function, but it gets the job done.\n",
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Basic Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the shape of this data.\n",
    "md.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION: Can this CSV file be opened in Excel? What about Apple's Numbers App?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the index. We see a RangeIndex because we did not specify a column to be an index when reading the csv.\n",
    "md.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the columns.\n",
    "md.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# I prefer .info() to .dtypes as the former also tells us how many null points we're dealing with\n",
    "md.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peak at the data\n",
    "md.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can we discern just from this look at the data? What about all the NaNs?\n",
    "\n",
    "We may want to set `raw_row_number` as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verify_integrity is set to false by default. Setting to True ensures a unique index.\n",
    "md.set_index(\"raw_row_number\", verify_integrity=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.head()\n",
    "# What did the first driver get cited for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access individual columns through dot-attribute notation (`md.subject_sex`) or through\n",
    "getitem dictionary-style notation (`md['subject_sex']`).\n",
    "\n",
    "QUESTION: Why might the latter be preferable even as the former is somewhat more natural to write?\n",
    "\n",
    "The return value is a Pandas Series; basically a one-column DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attribute notation\n",
    "md.subject_sex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getitem syntax (uses __.getitem__)\n",
    "md['outcome'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access multiple columns with a comma\n",
    "md[['department_name', 'citation_issued', 'reason_for_stop']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can index the rows by using the **loc** and **iloc** accessors.\n",
    "\n",
    "`loc` does *label-based* indexing.\n",
    "\n",
    "`iloc` performs *integer-based* indexing.\n",
    "\n",
    "You can use a comma separated list to access multiple fields at the same time.\n",
    "\n",
    "Both support the standard Python slicing operations `[start:end:step]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the rows for index IDs 3237323 and 2312594\n",
    "md.loc[[3237323,2312594]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get every tenth row starting from 4100, until 4150.\n",
    "md.iloc[4100:4150:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the first 5 rows and the first 5 columns\n",
    "md.iloc[:5, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the all the rows up to index 2312588 and the columns named 'subject_sex' and 'warning_issued'\n",
    "md.loc[:2312588, ['subject_sex', 'warning_issued']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Dealing with Data Types and NaN Cleaning \n",
    "![Office Space Meme](https://media.makeameme.org/created/i-was-told-592f12.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might be worried about the large number of NaNs in the dataset. Another way to quantify our null fields is by summing the result of applying `isnull()` to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why does this work? Think about what True and False are equivalent to.\n",
    "md.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But are the null fields really a problem? It depends. If `reason_for_search` is ALWAYS null, we have a problem, but if it's only null when `search_conducted` is False, we're in business."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.search_conducted == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md[md.search_conducted == True].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like `reason_for_search` is null only 56 times when a search has been conducted. An enterprising journalist might want to look at these 56 cases to see if there's anything fishy or if it's just a bookkeeping error (likely!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we hadn't done data conversions at import, we could do so now:\n",
    "\n",
    "Convert column \"subject_age\" to float64 dtype and \"subject_race\" to categorical type\n",
    "`md = md.astype({\"subject_age\": 'float', \"subject_race\": 'category'})`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#may want to use string methods to normalize string objects\n",
    "md.location.str.lower().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Exploring the Data More Deeply\n",
    "\n",
    "Here, the memes stop and we have to be more sober.\n",
    "\n",
    "Let's look at the kinds of values we find in various columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also normalize this\n",
    "md.subject_sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can apply functions to columns\n",
    "md.subject_age.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION: Who is the youngest person in this data set? What were they cited for? Does the citation pass the smell test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't execute until ready to see the answer\n",
    "%load solution/youngest.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are dozens of ways to plot age data. Let's look at two. For more on what KDE means, see [Kernel Density Estimation](https://en.wikipedia.org/wiki/Kernel_density_estimation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn is very pretty!\n",
    "sns.distplot(md.subject_age[md.subject_age.isnull()==False], kde= True, bins = 15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas (which uses Matplotlib under the hood) is less pretty by default, but very convenient\n",
    "md.subject_age.plot(kind='hist');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Exploring Race and Policing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.subject_race.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('max_rows', 210):\n",
    "    print(md.department_name.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to establish some baseline to determine if the proportion of White, Black, Hispanic, and Asian drivers being pulled over is disproportionate to their share of the population. Since we don't have good data for the whole state, let's compare select counties' traffic stops to their Census populations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcpd = md[md.department_name == 'Baltimore County Police Department']\n",
    "bcpd_by_race = bcpd.subject_race.value_counts(normalize=True)\n",
    "bcpd_by_race"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that Black motorists represent 49% of the people pulled over by the Baltimore County Police Department in 2013 - early 2014. What about Montgomery?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcpd = md[(md.department_name == 'MONTGOMERY') | (md.department_name == 'Montgomery County Police Department') |(md.department_name == 'Montgomery County Sherrif\\'s Office') ]\n",
    "mcpd_by_race = mcpd.subject_race.value_counts(normalize=True)\n",
    "mcpd_by_race"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EXERCISE: Create a new data frame for PG County "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't execute until ready to see the answer\n",
    "%load solution/pg.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [Census Data](https://www.census.gov/quickfacts/fact/table/princegeorgescountymaryland,baltimorecountymaryland,montgomerycountymaryland,US/PST045218)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baltimore_co_census = pd.Series([.572, .292,.055 ,.064,], index=['white', 'black', 'hispanic', 'asian/pacific islander'])\n",
    "moco_census = pd.Series([.438, .197, .196, .156,], index=['white', 'black', 'hispanic', 'asian/pacific islander'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moco_benchmark = pd.concat([mcpd_by_race, moco_census], keys=['police_stops', 'moco_census'], axis = 1)\n",
    "moco_benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s do the same sort of benchmark comparison for search and frisk rates. We can use the stopped population as our baseline, defining search rate to be the proportion of stopped people who were subsequently searched, and frisk rate as proportion of stopped people who were subsequently personally searched.\n",
    "\n",
    "We'll want to use pandas `GroupBy` functionality to implement the `split-apply-combine` pattern.\n",
    "\n",
    "The idea here is that we **split** the data by some key or set of keys then **apply** a function to each group and then **combine** the outputs back into a single DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In MoCo, how often are Hispanic drivers searched after being pulled over? White drivers? Asian drivers?\n",
    "mcpd.groupby('subject_race').search_conducted.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How often are drivers frisked during a stop?\n",
    "mcpd[mcpd.search_conducted == True].groupby('subject_race').search_person.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about statewide?\n",
    "md.groupby('subject_race').search_conducted.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md[md.search_conducted == True].groupby('subject_race').search_person.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![https://imgs.xkcd.com/comics/correlation.png](https://imgs.xkcd.com/comics/correlation.png)\n",
    "\n",
    "**\"Correlation doesn't imply causation, but it does waggle its eyebrows suggestively and gesture furtively while mouthing 'look over there'.\"** - [XKCD 552](https://www.explainxkcd.com/wiki/index.php/552:_Correlation)\n",
    "\n",
    "To get closer to causality, we can use the \"outcome test\" in which a lower search  success rate for one group relative to another is seen as evidence of bias against that group, as it suggests a lower evidentiary bar was applied when making search decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pay close attention to the figure for Hispanics\n",
    "md[md.search_conducted == True].groupby('subject_race').contraband_found.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md[md.search_conducted == True].groupby('subject_race').outcome.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcpd[mcpd.search_conducted == True].groupby('subject_race').outcome.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Closing Remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribution And Further Exploration\n",
    "\n",
    "- Jake VanderPlas: [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/): Free, CC License, available as a series of Jupyter Notebooks. Chapter 3 has strong coverage of Pandas.\n",
    "- [dataMontgomery](https://data.montgomerycountymd.gov/): Montgomery County, MD offers excellent datasets on various public services, including law enforcement. For example, its 1.4 million row/35 column dataset on traffic stops has data on vehicle make/model, city of origin of the driver, and exact geolocation of the stop.\n",
    "- [The Stanford Open Policing Project](https://openpolicing.stanford.edu/): See the whole dataset, plus a tutorial on how to work with it (unfortunately in R)\n",
    "- [Kaggle DataSets](https://www.kaggle.com/datasets): Collection of datasets, many amendable to machine learning techniques"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
